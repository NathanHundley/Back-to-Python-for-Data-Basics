{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1 align=\"center\">Python Data Science Guide</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Vectors, Matrices, and Arrays</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Vector</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:08:45.934293Z",
     "start_time": "2020-02-09T10:08:45.926350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "\n",
      "[[1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "### Use NumPy to create a vector\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Create a vector as a row\n",
    "vector_row = np.array([1, 2, 3])\n",
    "\n",
    "#Create a vector as a column\n",
    "vector_column = np.array([[1],\n",
    "                         [2],\n",
    "                          [3]])\n",
    "\n",
    "print(vector_row)\n",
    "print()\n",
    "print(vector_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:09:37.950329Z",
     "start_time": "2020-02-09T10:09:37.943347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create a matrix\n",
    "matrix = np.array([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Sparse Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:13:05.821233Z",
     "start_time": "2020-02-09T10:13:05.813255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 1)\t1\n",
      "  (2, 0)\t3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "#Create a matrix\n",
    "matrix = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [3, 0]])\n",
    "\n",
    "#Create compressed sparse row (CSR) matrix\n",
    "matrix_sparse = sparse.csr_matrix(matrix)\n",
    "\n",
    "print(matrix_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:15:34.208776Z",
     "start_time": "2020-02-09T10:15:34.198772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 1)\t1\n",
      "  (2, 0)\t3\n"
     ]
    }
   ],
   "source": [
    "#Create larger matrix\n",
    "matrix_large = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                        [3, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "#Create compressed sparse row (CSR) matrix\n",
    "matrix_large_sparse = sparse.csr_matrix(matrix_large)\n",
    "\n",
    "#View larger sparse matrix\n",
    "print(matrix_large_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting Elements</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:17:17.308582Z",
     "start_time": "2020-02-09T10:17:17.301640Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create row vector\n",
    "vector = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:17:35.939204Z",
     "start_time": "2020-02-09T10:17:35.923155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select third element of vector\n",
    "vector[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:17:57.074119Z",
     "start_time": "2020-02-09T10:17:57.068136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select second row, second column\n",
    "matrix[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:18:19.403188Z",
     "start_time": "2020-02-09T10:18:19.397201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select all elements of a vector\n",
    "vector[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:18:38.368363Z",
     "start_time": "2020-02-09T10:18:38.363377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select everything up to and including the third element\n",
    "vector[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:19:01.612323Z",
     "start_time": "2020-02-09T10:19:01.605369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select everything after the third element\n",
    "vector[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:19:22.754067Z",
     "start_time": "2020-02-09T10:19:22.749046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the last element\n",
    "vector[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:19:49.593966Z",
     "start_time": "2020-02-09T10:19:49.587951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the first two rows and all columns of a matrix\n",
    "matrix[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:20:31.337326Z",
     "start_time": "2020-02-09T10:20:31.331342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [5],\n",
       "       [8]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select all rows and the second column\n",
    "matrix[:,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Describing a Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:21:35.742196Z",
     "start_time": "2020-02-09T10:21:35.739201Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:22:16.435251Z",
     "start_time": "2020-02-09T10:22:16.419627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create matrix\n",
    "matrix = np.array([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]])\n",
    "\n",
    "#View number of rows and columns\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:22:35.625480Z",
     "start_time": "2020-02-09T10:22:35.620487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View number of elements (rows * columns)\n",
    "matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:22:51.281597Z",
     "start_time": "2020-02-09T10:22:51.275613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View number of dimensions\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Applying Operations to Elements</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:39:31.639409Z",
     "start_time": "2020-02-09T10:39:31.620458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 102, 103],\n",
       "       [104, 105, 106],\n",
       "       [107, 108, 109]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "#Create function that adds 100 to something\n",
    "add_100 = lambda i: i + 100\n",
    "\n",
    "#Create vectorized function\n",
    "vectorized_add_100 = np.vectorize(add_100)\n",
    "\n",
    "#Apply function to all elements in matrix\n",
    "vectorized_add_100(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding the Maximum and Minimum Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:41:30.515798Z",
     "start_time": "2020-02-09T10:41:30.507816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "#Return maximum element\n",
    "np.max(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:41:44.809783Z",
     "start_time": "2020-02-09T10:41:44.803829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return minimum element\n",
    "np.min(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:42:23.066465Z",
     "start_time": "2020-02-09T10:42:23.059484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum element in each column\n",
    "np.max(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:42:42.598871Z",
     "start_time": "2020-02-09T10:42:42.593888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the maximum element in each row\n",
    "np.max(matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculating the Average, Variance, and Standard Deviation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:43:52.773047Z",
     "start_time": "2020-02-09T10:43:52.767061Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:44:04.201535Z",
     "start_time": "2020-02-09T10:44:04.194558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return mean\n",
    "np.mean(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:44:17.192267Z",
     "start_time": "2020-02-09T10:44:17.186314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return variance\n",
    "np.var(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:44:33.184571Z",
     "start_time": "2020-02-09T10:44:33.178588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.581988897471611"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return standard deviation\n",
    "np.std(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:45:02.400654Z",
     "start_time": "2020-02-09T10:45:02.394670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 6.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the mean value in each column\n",
    "np.mean(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reshaping Arrays</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:47:07.132454Z",
     "start_time": "2020-02-09T10:47:07.123477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create 4x3 matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9],\n",
    "                  [10, 11, 12]])\n",
    "\n",
    "#Reshape matrix into 2x6 matrix\n",
    "matrix.reshape(2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:47:58.351611Z",
     "start_time": "2020-02-09T10:47:58.345626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshape to one row with as many columns as needed\n",
    "matrix.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:48:37.559481Z",
     "start_time": "2020-02-09T10:48:37.553497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you provide one target reshape will create a 1D array of that length\n",
    "matrix.reshape(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Transposing a Vector or Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:49:39.126221Z",
     "start_time": "2020-02-09T10:49:39.121224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 5, 8],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create a matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "#Transpose matrix\n",
    "matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:50:37.947305Z",
     "start_time": "2020-02-09T10:50:37.939329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transpose a row vector into a column vector\n",
    "np.array([[1, 2, 3, 4, 5, 6]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Flattening a Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:51:42.211621Z",
     "start_time": "2020-02-09T10:51:42.203641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create a matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "#Flatten matrix\n",
    "matrix.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding the Rank of a Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:55:47.496706Z",
     "start_time": "2020-02-09T10:55:47.485758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 1, 1],\n",
    "                  [1, 1, 10],\n",
    "                  [1, 1, 15]])\n",
    "\n",
    "#Return matrix rank\n",
    "np.linalg.matrix_rank(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculating the Determinant</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:57:09.576498Z",
     "start_time": "2020-02-09T10:57:09.561539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [2, 4, 6],\n",
    "                  [3, 8, 9]])\n",
    "\n",
    "#Return determinant of matrix\n",
    "np.linalg.det(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting the Diagonal of a Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:58:17.528776Z",
     "start_time": "2020-02-09T10:58:17.520798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [2, 4, 6],\n",
    "                  [3, 8, 9]])\n",
    "\n",
    "#Return diagonal elements\n",
    "matrix.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:58:56.645097Z",
     "start_time": "2020-02-09T10:58:56.639105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return the diagonal one above the main diagonal\n",
    "matrix.diagonal(offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T10:59:16.749905Z",
     "start_time": "2020-02-09T10:59:16.743920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return diagonal one below the main diagonal\n",
    "matrix.diagonal(offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculating the Trace of a Matrix</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace of a matrix is the sum of the diagonal elements and is oftn used under the hood of machine learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:00:22.424411Z",
     "start_time": "2020-02-09T11:00:22.416438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                  [2, 4, 6],\n",
    "                  [3, 8, 9]])\n",
    "\n",
    "#Return trace\n",
    "matrix.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:01:30.159029Z",
     "start_time": "2020-02-09T11:01:30.154033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return diagonal and sum elements\n",
    "sum(matrix.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding Eigenvalues and Eigenvectors</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvectors are vectors that change only in scale (not direction). Eigenvalues are the factors by which the eigenvectors are scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:03:01.050563Z",
     "start_time": "2020-02-09T11:03:01.032648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55075847,  0.74003145, -3.29078992])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, -1, 3],\n",
    "                  [1, 1, 6],\n",
    "                  [3, 8, 9]])\n",
    "\n",
    "#Calculate eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
    "\n",
    "#View eigenvalues\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:03:12.054812Z",
     "start_time": "2020-02-09T11:03:12.048830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17622017, -0.96677403, -0.53373322],\n",
       "       [-0.435951  ,  0.2053623 , -0.64324848],\n",
       "       [-0.88254925,  0.15223105,  0.54896288]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View eigenvectors\n",
    "eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculating Dot Products</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:08:47.312402Z",
     "start_time": "2020-02-09T11:08:47.305420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create two vectors\n",
    "vector_a = np.array([1, 2, 3])\n",
    "vector_b = np.array([4, 5, 6])\n",
    "\n",
    "#Calculate dot product\n",
    "np.dot(vector_a, vector_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:09:13.046396Z",
     "start_time": "2020-02-09T11:09:13.040444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dot product can also be calculated by.\n",
    "vector_a @ vector_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Adding and Subtracting Matrices</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:10:39.810302Z",
     "start_time": "2020-02-09T11:10:39.799331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  4,  2],\n",
       "       [ 2,  4,  2],\n",
       "       [ 2,  4, 10]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix_a = np.array([[1, 1, 1],\n",
    "                  [1, 1, 1],\n",
    "                  [1, 1, 2]])\n",
    "\n",
    "matrix_b = np.array([[1, 3, 1],\n",
    "                    [1, 3, 1],\n",
    "                    [1, 3, 8]])\n",
    "\n",
    "#Add two matrices\n",
    "np.add(matrix_a, matrix_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:10:59.495787Z",
     "start_time": "2020-02-09T11:10:59.488802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -2,  0],\n",
       "       [ 0, -2,  0],\n",
       "       [ 0, -2, -6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subtract two matrices\n",
    "np.subtract(matrix_a, matrix_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:11:16.781691Z",
     "start_time": "2020-02-09T11:11:16.775706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  4,  2],\n",
       "       [ 2,  4,  2],\n",
       "       [ 2,  4, 10]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can also....\n",
    "matrix_a + matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multiplying Matrices</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:12:32.614298Z",
     "start_time": "2020-02-09T11:12:32.605348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5],\n",
       "       [3, 7]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix_a = np.array([[1, 1],\n",
    "                    [1, 2]])\n",
    "\n",
    "matrix_b = np.array([[1, 3],\n",
    "                    [1, 2]])\n",
    "\n",
    "#Multiply two matrices\n",
    "np.dot(matrix_a, matrix_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:12:48.238360Z",
     "start_time": "2020-02-09T11:12:48.232377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5],\n",
       "       [3, 7]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can also...\n",
    "matrix_a @ matrix_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:13:10.629418Z",
     "start_time": "2020-02-09T11:13:10.622472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [1, 4]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we want element-wise multiplication\n",
    "matrix_a * matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inverting a Matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:14:11.287566Z",
     "start_time": "2020-02-09T11:14:11.271609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.66666667,  1.33333333],\n",
       "       [ 0.66666667, -0.33333333]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create matrix\n",
    "matrix = np.array([[1, 4],\n",
    "                  [2, 5]])\n",
    "\n",
    "#Calculate inverse of matrix\n",
    "np.linalg.inv(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:15:13.333121Z",
     "start_time": "2020-02-09T11:15:13.327144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can get the Identity matrix by multiuply a matrix by it's inverse\n",
    "matrix @ np.linalg.inv(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generating Random Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:16:11.831710Z",
     "start_time": "2020-02-09T11:16:11.823767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37454012, 0.95071431, 0.73199394])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Generate three random floats between 0.0 and 1.0\n",
    "np.random.random(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:16:58.534516Z",
     "start_time": "2020-02-09T11:16:58.527534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate three random integers between 1 and 10\n",
    "np.random.randint(0, 11, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:17:33.358944Z",
     "start_time": "2020-02-09T11:17:33.351962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27904129,  1.01051528, -0.58087813])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Draw three numbers from a normal distribution with mean 0.0 and standard deviation of 1.0\n",
    "np.random.normal(0.0, 1.0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:18:12.053298Z",
     "start_time": "2020-02-09T11:18:12.039333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.49344971, -0.82717731,  0.09910677])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Draw three numbers from a logistic distribution with mean 0.0 and scale of 1.0\n",
    "np.random.logistic(0.0, 1.0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:18:38.574244Z",
     "start_time": "2020-02-09T11:18:38.567265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.43194502, 1.29122914, 1.61185289])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Draw three numbers greater than or equal to 1.0 and less than 2.0\n",
    "np.random.uniform(1.0, 2.0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:21:50.210190Z",
     "start_time": "2020-02-09T11:21:50.205204Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Loading Data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading a Sample Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:23:41.594053Z",
     "start_time": "2020-02-09T11:23:41.486347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "#Load digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#Create feature and target matrix/vectors\n",
    "features, target = digits.data, digits.target\n",
    "\n",
    "#View first observation\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Simulated Dataset</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:26:44.524862Z",
     "start_time": "2020-02-09T11:26:44.518912Z"
    }
   },
   "source": [
    "<h4>Simulating Regression Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:26:16.582578Z",
     "start_time": "2020-02-09T11:26:16.573602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[ 0.85243333  0.18645431 -0.66178646]\n",
      " [-0.48536355 -0.77282521 -0.23681861]\n",
      " [-0.84679372  0.47323762 -0.07282891]]\n",
      "Target Vector\n",
      " [ 57.50085105 -62.43054535 -51.50692142]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "#Generate features matrix, target vector, and the true coefficents\n",
    "features, target, coefficients = make_regression(n_samples = 100,\n",
    "                                                n_features = 3,\n",
    "                                                n_informative = 3,\n",
    "                                                n_targets = 1,\n",
    "                                                noise = 0.0,\n",
    "                                                coef = True,\n",
    "                                                random_state = 42)\n",
    "\n",
    "#View feature matrix and target vector\n",
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Simulating Classification Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:28:37.140469Z",
     "start_time": "2020-02-09T11:28:37.132493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[-0.0550468  -0.07689964  1.01423611]\n",
      " [ 0.85772085  1.36799979  1.1599394 ]\n",
      " [-0.801402    0.11471707 -0.53470213]]\n",
      "Target Vector\n",
      " [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 100,\n",
    "                                        n_features = 3,\n",
    "                                        n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                        n_classes = 2,\n",
    "                                        weights = [.25, .75],\n",
    "                                        random_state = 42)\n",
    "\n",
    "#View feature matrix and target vector\n",
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Simulating Clustering Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:31:49.699964Z",
     "start_time": "2020-02-09T11:31:49.693978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix\n",
      " [[-7.30302405 -7.63753321]\n",
      " [ 5.04663744  1.35773753]\n",
      " [-2.74393482  9.28556615]]\n",
      "Target Vector\n",
      " [2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "#Generate features matrix and target vector\n",
    "features, target = make_blobs(n_samples = 100,\n",
    "                            n_features = 2,\n",
    "                              centers = 3,\n",
    "                              cluster_std = 0.5,\n",
    "                              shuffle = True,\n",
    "                              random_state=42)\n",
    "                                        \n",
    "#View feature matrix and target vector\n",
    "print('Feature Matrix\\n', features[:3])\n",
    "print('Target Vector\\n', target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T11:32:08.383892Z",
     "start_time": "2020-02-09T11:32:08.198215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#View scatterplot of simulated clusters\n",
    "plt.scatter(features[:,0], features[:,1], c=target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading a CSV File</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:07:09.390212Z",
     "start_time": "2020-02-09T12:07:09.376248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integer</th>\n",
       "      <th>datetime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   integer             datetime  category\n",
       "0        5  2015-01-01 00:00:00         0\n",
       "1        5  2015-01-01 00:00:01         0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#File location\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/data.csv'\n",
    "\n",
    "#Load dataset\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#View first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading an Excel File</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:07:31.519270Z",
     "start_time": "2020-02-09T12:07:31.440479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:188: FutureWarning: The `sheetname` keyword is deprecated, use `sheet_name` instead\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2015-01-01 00:00:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5 2015-01-01 00:00:00  0\n",
       "0  5 2015-01-01 00:00:01  0\n",
       "1  9 2015-01-01 00:00:02  0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#File location\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/data.xlsx'\n",
    "\n",
    "#Load dataset\n",
    "dataframe = pd.read_excel(location, sheetname=0, header=1)\n",
    "\n",
    "#View first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading a JSON File</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:08:44.522189Z",
     "start_time": "2020-02-09T12:08:44.491260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integer</th>\n",
       "      <th>datetime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   integer            datetime  category\n",
       "0        5 2015-01-01 00:00:00         0\n",
       "1        5 2015-01-01 00:00:01         0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#File location\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/data.json'\n",
    "\n",
    "#Load dataset\n",
    "dataframe = pd.read_json(location, orient='columns')\n",
    "\n",
    "#View first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Querying a SQL Database</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:11:55.572992Z",
     "start_time": "2020-02-09T12:11:55.554040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "      <th>preTestScore</th>\n",
       "      <th>postTestScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason</td>\n",
       "      <td>Miller</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Molly</td>\n",
       "      <td>Jacobson</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name  age  preTestScore  postTestScore\n",
       "0      Jason    Miller   42             4             25\n",
       "1      Molly  Jacobson   52            24             94"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Create a connection to the database\n",
    "database_connection = create_engine('sqlite:///C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/sample.db')\n",
    "\n",
    "#Load data\n",
    "dataframe = pd.read_sql_query('SELECT * FROM data', database_connection)\n",
    "\n",
    "#View first two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:12:34.311390Z",
     "start_time": "2020-02-09T12:12:34.305419Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Data Wrangling</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Data Frame</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:14:47.138003Z",
     "start_time": "2020-02-09T12:14:47.121046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   25   False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create DataFrame\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "#Add columns\n",
    "dataframe['Name'] = ['Jacky Jackson', 'Steven Stevenson']\n",
    "dataframe['Age'] = [38, 25]\n",
    "dataframe['Driver'] = [True, False]\n",
    "\n",
    "#Show dataframe\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:16:34.667287Z",
     "start_time": "2020-02-09T12:16:34.652321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Molly Mooney</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   25   False\n",
       "2      Molly Mooney   40    True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add a new row to the dataframe\n",
    "\n",
    "#Create row\n",
    "new_person = pd.Series(['Molly Mooney', 40, True], index=['Name', 'Age', 'Driver'])\n",
    "\n",
    "#Append row\n",
    "dataframe.append(new_person, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Describing the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:17:59.525929Z",
     "start_time": "2020-02-09T12:17:59.504984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Show two rows\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:18:19.390696Z",
     "start_time": "2020-02-09T12:18:19.384712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 6)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of rows and columns\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:18:39.546076Z",
     "start_time": "2020-02-09T12:18:39.521175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>756.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.397989</td>\n",
       "      <td>0.342727</td>\n",
       "      <td>0.351866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.259049</td>\n",
       "      <td>0.474802</td>\n",
       "      <td>0.477734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Survived      SexCode\n",
       "count  756.000000  1313.000000  1313.000000\n",
       "mean    30.397989     0.342727     0.351866\n",
       "std     14.259049     0.474802     0.477734\n",
       "min      0.170000     0.000000     0.000000\n",
       "25%     21.000000     0.000000     0.000000\n",
       "50%     28.000000     0.000000     0.000000\n",
       "75%     39.000000     1.000000     1.000000\n",
       "max     71.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show statistics\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Navigating DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:21:34.080184Z",
     "start_time": "2020-02-09T12:21:34.066197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        Allen, Miss Elisabeth Walton\n",
       "PClass                               1st\n",
       "Age                                   29\n",
       "Sex                               female\n",
       "Survived                               1\n",
       "SexCode                                1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Select first row\n",
    "dataframe.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:22:02.647709Z",
     "start_time": "2020-02-09T12:22:02.632764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass   Age     Sex  \\\n",
       "1                    Allison, Miss Helen Loraine    1st   2.0  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.0    male   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.0  female   \n",
       "\n",
       "   Survived  SexCode  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting second through fourth rows\n",
    "dataframe.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:22:43.896032Z",
     "start_time": "2020-02-09T12:22:43.880113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass   Age     Sex  \\\n",
       "0                   Allen, Miss Elisabeth Walton    1st  29.0  female   \n",
       "1                    Allison, Miss Helen Loraine    1st   2.0  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.0    male   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.0  female   \n",
       "\n",
       "   Survived  SexCode  \n",
       "0         1        1  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting first four rows\n",
    "dataframe.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:23:18.007617Z",
     "start_time": "2020-02-09T12:23:18.001600Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set index\n",
    "dataframe = dataframe.set_index(dataframe['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:23:35.477972Z",
     "start_time": "2020-02-09T12:23:35.464008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        Allen, Miss Elisabeth Walton\n",
       "PClass                               1st\n",
       "Age                                   29\n",
       "Sex                               female\n",
       "Survived                               1\n",
       "SexCode                                1\n",
       "Name: Allen, Miss Elisabeth Walton, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show row\n",
    "dataframe.loc['Allen, Miss Elisabeth Walton']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting Rows Based on Conditionals</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:25:01.537173Z",
     "start_time": "2020-02-09T12:25:01.514236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Show top two rows where column 'sex' is 'female'\n",
    "dataframe[dataframe['Sex'] == 'female'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:26:12.311229Z",
     "start_time": "2020-02-09T12:26:12.296302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Crosby, Mrs Edward Gifford (Catherine Elizabet...</td>\n",
       "      <td>1st</td>\n",
       "      <td>69.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name PClass   Age     Sex  \\\n",
       "73  Crosby, Mrs Edward Gifford (Catherine Elizabet...    1st  69.0  female   \n",
       "\n",
       "    Survived  SexCode  \n",
       "73         1        1  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show rows that meet two conditions\n",
    "dataframe[(dataframe['Sex'] == 'female') & (dataframe['Age'] >= 65) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Replacing Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:27:19.577876Z",
     "start_time": "2020-02-09T12:27:19.561919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Woman\n",
       "1    Woman\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Replace values, show two rows\n",
    "dataframe['Sex'].replace('female', 'Woman').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:28:16.813449Z",
     "start_time": "2020-02-09T12:28:16.806464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Woman\n",
       "1    Woman\n",
       "2      Man\n",
       "3    Woman\n",
       "4      Man\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace \"female\" and \"male\" with \"Woman\" and \"Man\"\n",
    "dataframe['Sex'].replace([\"female\", \"male\"], [\"Woman\", \"Man\"]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:28:59.900020Z",
     "start_time": "2020-02-09T12:28:59.882043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass Age     Sex Survived SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29  female      One     One\n",
       "1   Allison, Miss Helen Loraine    1st   2  female        0     One"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace values across entire dataset, show two rows\n",
    "dataframe.replace(1, \"One\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:29:44.067735Z",
     "start_time": "2020-02-09T12:29:44.040802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>First</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>First</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton  First  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine  First   2.0  female         0        1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace values using regex\n",
    "dataframe.replace(r\"1st\", \"First\", regex=True).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Renaming Columns</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:31:15.321146Z",
     "start_time": "2020-02-09T12:31:15.296237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name Passenger Class   Age     Sex  Survived  \\\n",
       "0  Allen, Miss Elisabeth Walton             1st  29.0  female         1   \n",
       "1   Allison, Miss Helen Loraine             1st   2.0  female         0   \n",
       "\n",
       "   SexCode  \n",
       "0        1  \n",
       "1        1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Rename column, show two rows\n",
    "dataframe.rename(columns={'PClass': 'Passenger Class'}).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:32:19.321344Z",
     "start_time": "2020-02-09T12:32:19.304389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name Passenger Class   Age  Gender  Survived  \\\n",
       "0  Allen, Miss Elisabeth Walton             1st  29.0  female         1   \n",
       "1   Allison, Miss Helen Loraine             1st   2.0  female         0   \n",
       "\n",
       "   SexCode  \n",
       "0        1  \n",
       "1        1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename multiple columns, show two rows\n",
    "dataframe.rename(columns={'PClass': 'Passenger Class', 'Sex': 'Gender'}).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding the Minimum, Maximum, Sum, Average, and Count</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:34:42.673377Z",
     "start_time": "2020-02-09T12:34:42.655450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum: 71.0\n",
      "Minimum: 0.17\n",
      "Mean: 30.397989417989415\n",
      "Sum: 22980.88\n",
      "Count: 756\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Calculate statistics\n",
    "print('Maximum:', dataframe['Age'].max())\n",
    "print('Minimum:', dataframe['Age'].min())\n",
    "print('Mean:', dataframe['Age'].mean())\n",
    "print('Sum:', dataframe['Age'].sum())\n",
    "print('Count:', dataframe['Age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:35:14.647074Z",
     "start_time": "2020-02-09T12:35:14.637094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        1313\n",
       "PClass      1313\n",
       "Age          756\n",
       "Sex         1313\n",
       "Survived    1313\n",
       "SexCode     1313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show counts for all variables\n",
    "dataframe.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding Unique Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:35:55.431862Z",
     "start_time": "2020-02-09T12:35:55.416920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Select unique values\n",
    "dataframe[\"Sex\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:36:16.887079Z",
     "start_time": "2020-02-09T12:36:16.871121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      851\n",
       "female    462\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show value counts\n",
    "dataframe['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:37:00.085017Z",
     "start_time": "2020-02-09T12:37:00.078038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of unique values\n",
    "dataframe['PClass'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Handling Missing Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:37:53.759930Z",
     "start_time": "2020-02-09T12:37:53.741978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aubert, Mrs Leontine Pauline</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Barkworth, Mr Algernon H</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name PClass  Age     Sex  Survived  SexCode\n",
       "12  Aubert, Mrs Leontine Pauline    1st  NaN  female         1        1\n",
       "13      Barkworth, Mr Algernon H    1st  NaN    male         1        0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Select missing values, show two rows\n",
    "dataframe[dataframe['Age'].isnull()].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:39:11.638338Z",
     "start_time": "2020-02-09T12:39:11.630360Z"
    }
   },
   "outputs": [],
   "source": [
    "#Replace values with NaN\n",
    "import numpy as np\n",
    "\n",
    "dataframe['Sex'] = dataframe['Sex'].replace('male', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:39:45.610740Z",
     "start_time": "2020-02-09T12:39:45.598781Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load data, set missing values\n",
    "dataframe = pd.read_csv(location, na_values=[np.nan, 'NONE', -999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deleting a Columns</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:40:41.333668Z",
     "start_time": "2020-02-09T12:40:41.310694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st  female         0        1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Delete column\n",
    "dataframe.drop('Age', axis=1).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:41:14.637313Z",
     "start_time": "2020-02-09T12:41:14.623350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st         1        1\n",
       "1   Allison, Miss Helen Loraine    1st         0        1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete multiple columns\n",
    "dataframe.drop(['Age', 'Sex'], axis=1).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:42:03.479156Z",
     "start_time": "2020-02-09T12:42:03.464194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine   2.0  female         0        1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If column does not have a name, you can drop it by column index\n",
    "dataframe.drop(dataframe.columns[1], axis=1).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:42:54.949818Z",
     "start_time": "2020-02-09T12:42:54.942836Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create a new DataFrame\n",
    "dataframe_name_dropped = dataframe.drop(dataframe.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deleting Rows</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:43:43.353634Z",
     "start_time": "2020-02-09T12:43:43.330694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Delete rows, show first two rows\n",
    "dataframe[dataframe['Sex'] != 'male'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:44:52.773960Z",
     "start_time": "2020-02-09T12:44:52.758001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "1          Allison, Miss Helen Loraine    1st   2.0  female         0        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0    male         0        0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete row by index, show first two rows\n",
    "dataframe[dataframe.index != 0].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dropping Duplicate Rows</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:45:42.814187Z",
     "start_time": "2020-02-09T12:45:42.785263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Drop duplicates with unique values across all columns, show first two rows\n",
    "dataframe.drop_duplicates().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:46:53.576992Z",
     "start_time": "2020-02-09T12:46:53.566020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in the Original DataFrame: 1313\n",
      "Number of Rows After Deduping: 1313\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Rows in the Original DataFrame:\", len(dataframe))\n",
    "print(\"Number of Rows After Deduping:\", len(dataframe.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:47:40.152631Z",
     "start_time": "2020-02-09T12:47:40.135708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "0         Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0    male         0        0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop duplicates from specific column\n",
    "dataframe.drop_duplicates(subset=['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grouping Rows by Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:49:05.182276Z",
     "start_time": "2020-02-09T12:49:05.161280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>29.396424</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>31.014338</td>\n",
       "      <td>0.166863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  Survived  SexCode\n",
       "Sex                                 \n",
       "female  29.396424  0.666667      1.0\n",
       "male    31.014338  0.166863      0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Group rows by the values of the column 'Sex', calculate mean of each group\n",
    "dataframe.groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:50:08.183221Z",
     "start_time": "2020-02-09T12:50:08.174245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    863\n",
       "1    450\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group rows, count rows\n",
    "dataframe.groupby('Survived')['Name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:51:03.281420Z",
     "start_time": "2020-02-09T12:51:03.269453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0           24.901408\n",
       "        1           30.867143\n",
       "male    0           32.320780\n",
       "        1           25.951875\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group by a first column, then group that by a second column, calculate mean\n",
    "dataframe.groupby(['Sex', 'Survived'])['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grouping Rows by Time</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:58:50.454024Z",
     "start_time": "2020-02-09T12:58:50.423069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>85846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>100344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>100821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-02</th>\n",
       "      <td>100224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>100329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16</th>\n",
       "      <td>10417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11        85846\n",
       "2017-06-18       100344\n",
       "2017-06-25       100821\n",
       "2017-07-02       100224\n",
       "2017-07-09       100329\n",
       "2017-07-16        10417"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Create date range\n",
    "time_index = pd.date_range('06/06/2017', periods=100000, freq='30S')\n",
    "\n",
    "#Create dataframe\n",
    "dataframe = pd.DataFrame(index=time_index)\n",
    "\n",
    "#Create column of random values\n",
    "dataframe['Sale_Amount'] = np.random.randint(1, 10, 100000)\n",
    "\n",
    "#Group rows by week, calculate sum per week\n",
    "dataframe.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:59:25.872513Z",
     "start_time": "2020-02-09T12:59:25.852597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>4.967940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>4.989211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>4.974033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-23</th>\n",
       "      <td>5.008173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11     4.967940\n",
       "2017-06-25     4.989211\n",
       "2017-07-09     4.974033\n",
       "2017-07-23     5.008173"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group by two weeks, calculate means\n",
    "dataframe.resample('2W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T12:59:51.046906Z",
     "start_time": "2020-02-09T12:59:51.028932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-30        72000\n",
       "2017-07-31        28000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group by month, count rows\n",
    "dataframe.resample('M').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Looping Over a Column</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:01:31.460028Z",
     "start_time": "2020-02-09T13:01:31.444071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLEN, MISS ELISABETH WALTON\n",
      "ALLISON, MISS HELEN LORAINE\n",
      "ALLISON, MR HUDSON JOSHUA CREIGHTON\n",
      "ALLISON, MRS HUDSON JC (BESSIE WALDO DANIELS)\n",
      "ALLISON, MASTER HUDSON TREVOR\n",
      "ANDERSON, MR HARRY\n",
      "ANDREWS, MISS KORNELIA THEODOSIA\n",
      "ANDREWS, MR THOMAS, JR\n",
      "APPLETON, MRS EDWARD DALE (CHARLOTTE LAMSON)\n",
      "ARTAGAVEYTIA, MR RAMON\n",
      "ASTOR, COLONEL JOHN JACOB\n",
      "ASTOR, MRS JOHN JACOB (MADELEINE TALMADGE FORCE)\n",
      "AUBERT, MRS LEONTINE PAULINE\n",
      "BARKWORTH, MR ALGERNON H\n",
      "BAUMANN, MR JOHN D\n",
      "BAXTER, MRS JAMES (HELENE DELAUDENIERE CHAPUT)\n",
      "BAXTER, MR QUIGG EDMOND\n",
      "BEATTIE, MR THOMSON\n",
      "BECKWITH, MR RICHARD LEONARD\n",
      "BECKWITH, MRS RICHARD LEONARD (SALLIE MONYPENY)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Print first twenty names uppercased\n",
    "for name in dataframe['Name'][:20]:\n",
    "    print(name.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:02:36.240983Z",
     "start_time": "2020-02-09T13:02:36.235996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLEN, MISS ELISABETH WALTON',\n",
       " 'ALLISON, MISS HELEN LORAINE',\n",
       " 'ALLISON, MR HUDSON JOSHUA CREIGHTON',\n",
       " 'ALLISON, MRS HUDSON JC (BESSIE WALDO DANIELS)',\n",
       " 'ALLISON, MASTER HUDSON TREVOR',\n",
       " 'ANDERSON, MR HARRY',\n",
       " 'ANDREWS, MISS KORNELIA THEODOSIA',\n",
       " 'ANDREWS, MR THOMAS, JR',\n",
       " 'APPLETON, MRS EDWARD DALE (CHARLOTTE LAMSON)',\n",
       " 'ARTAGAVEYTIA, MR RAMON',\n",
       " 'ASTOR, COLONEL JOHN JACOB',\n",
       " 'ASTOR, MRS JOHN JACOB (MADELEINE TALMADGE FORCE)',\n",
       " 'AUBERT, MRS LEONTINE PAULINE',\n",
       " 'BARKWORTH, MR ALGERNON H',\n",
       " 'BAUMANN, MR JOHN D',\n",
       " 'BAXTER, MRS JAMES (HELENE DELAUDENIERE CHAPUT)',\n",
       " 'BAXTER, MR QUIGG EDMOND',\n",
       " 'BEATTIE, MR THOMSON',\n",
       " 'BECKWITH, MR RICHARD LEONARD',\n",
       " 'BECKWITH, MRS RICHARD LEONARD (SALLIE MONYPENY)']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show first twenty names uppercased using list comprehension\n",
    "[name.upper() for name in dataframe['Name'][:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Applying a Function Over All Elements in a Column</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:03:51.641206Z",
     "start_time": "2020-02-09T13:03:51.627218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ALLEN, MISS ELISABETH WALTON\n",
       "1     ALLISON, MISS HELEN LORAINE\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Create function\n",
    "def uppercase(x):\n",
    "    return x.upper()\n",
    "\n",
    "#Apply function, show two rows\n",
    "dataframe['Name'].apply(uppercase)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Applying a Function to Groups</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:04:54.925041Z",
     "start_time": "2020-02-09T13:04:54.895121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>288</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "      <td>468</td>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  PClass  Age  Sex  Survived  SexCode\n",
       "Sex                                              \n",
       "female   462     462  288  462       462      462\n",
       "male     851     851  468  851       851      851"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "location = 'C:/Users/nhundley/Python/challenge_tests/simulated_datasets-master/simulated_datasets-master/titanic.csv'\n",
    "dataframe = pd.read_csv(location)\n",
    "\n",
    "#Group rows, apply function to groups\n",
    "dataframe.groupby('Sex').apply(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Concatenating DataFranes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:08:46.592353Z",
     "start_time": "2020-02-09T13:08:46.570437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Bawlner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last\n",
       "0  1   Alex  Anderson\n",
       "1  2    Amy  Ackerman\n",
       "2  3  Allen       Ali\n",
       "0  4  Billy    Bonder\n",
       "1  5  Brian     Black\n",
       "2  6   Bran   Bawlner"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create data and convert to dataframes\n",
    "data_a = {'id': ['1', '2', '3'],\n",
    "         'first': ['Alex', 'Amy', 'Allen'],\n",
    "         'last': ['Anderson', 'Ackerman', 'Ali']}\n",
    "\n",
    "dataframe_a = pd.DataFrame(data_a, columns = ['id', 'first', 'last'])\n",
    "\n",
    "data_b = {'id': ['4', '5', '6'],\n",
    "         'first': ['Billy', 'Brian', 'Bran'],\n",
    "         'last': ['Bonder', 'Black', 'Bawlner']}\n",
    "\n",
    "dataframe_b = pd.DataFrame(data_b, columns = ['id', 'first', 'last'])\n",
    "\n",
    "#Concatenate DataFrames by rows\n",
    "pd.concat([dataframe_a, dataframe_b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:09:21.174505Z",
     "start_time": "2020-02-09T13:09:21.157550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Bawlner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last id  first     last\n",
       "0  1   Alex  Anderson  4  Billy   Bonder\n",
       "1  2    Amy  Ackerman  5  Brian    Black\n",
       "2  3  Allen       Ali  6   Bran  Bawlner"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate by columns\n",
    "pd.concat([dataframe_a, dataframe_b], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Merging DataFrames</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:13:18.159097Z",
     "start_time": "2020-02-09T13:13:18.118591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           3  Alice Bees        23456\n",
       "1           4  Tim Horton         2512"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create DataFrames\n",
    "\n",
    "employee_data = {'employee_id': ['1', '2', '3', '4'],\n",
    "                'name': ['Amy Jones', 'Allen Keys', 'Alice Bees', 'Tim Horton']}\n",
    "dataframe_employees = pd.DataFrame(employee_data, columns = ['employee_id', 'name'])\n",
    "\n",
    "sales_data = {'employee_id': ['3', '4', '5', '6'],\n",
    "                'total_sales': [23456, 2512, 2345, 1455]}\n",
    "dataframe_sales = pd.DataFrame(sales_data, columns = ['employee_id', 'total_sales'])\n",
    "\n",
    "#Merge DataFrames, defaults to inner join\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:13:50.354840Z",
     "start_time": "2020-02-09T13:13:50.339880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amy Jones</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allen Keys</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1455.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           1   Amy Jones          NaN\n",
       "1           2  Allen Keys          NaN\n",
       "2           3  Alice Bees      23456.0\n",
       "3           4  Tim Horton       2512.0\n",
       "4           5         NaN       2345.0\n",
       "5           6         NaN       1455.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge DataFrames outer\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:14:08.076047Z",
     "start_time": "2020-02-09T13:14:08.065076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amy Jones</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allen Keys</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           1   Amy Jones          NaN\n",
       "1           2  Allen Keys          NaN\n",
       "2           3  Alice Bees      23456.0\n",
       "3           4  Tim Horton       2512.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge DataFrames left\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:14:20.122557Z",
     "start_time": "2020-02-09T13:14:20.106935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           3  Alice Bees        23456\n",
       "1           4  Tim Horton         2512\n",
       "2           5         NaN         2345\n",
       "3           6         NaN         1455"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge DataFrames right\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T13:15:13.224883Z",
     "start_time": "2020-02-09T13:15:13.209952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           3  Alice Bees        23456\n",
       "1           4  Tim Horton         2512"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify columns in each dataframe to merge on\n",
    "pd.merge(dataframe_employees, dataframe_sales, left_on='employee_id', right_on='employee_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Handling Numerical Data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rescaling a Feature Using Min-Max Scaling</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-max scaling uses the minimum and maximum values of a feature to rescale values to within a range. Specifically, min-max calculates: x' = (x - min) / (max - min). Often used for neaural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T20:57:08.549060Z",
     "start_time": "2020-02-09T20:57:08.537092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Create feature\n",
    "feature = np.array([[-500.5],\n",
    "                   [-100.1],\n",
    "                   [0],\n",
    "                   [100.1],\n",
    "                   [900.9]])\n",
    "\n",
    "#Create scaler\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "#Scale feature\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "#Show feature\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standardizing a Feature</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use standardization to transform the data so that the mean is 0 and standard deviation is 1. Standardization is calculated as: x' = (x - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:00:52.320550Z",
     "start_time": "2020-02-09T21:00:52.312546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Create function\n",
    "x = np.array([[-1000.1],\n",
    "             [-200.2],\n",
    "             [500.5],\n",
    "             [600.6],\n",
    "             [9000.9]])\n",
    "\n",
    "#Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "#Transform the feature\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "#Show feature\n",
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:03:28.231541Z",
     "start_time": "2020-02-09T21:03:28.225558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Standard deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Print mean and standard deviation\n",
    "print(\"Mean:\", round(standardized.mean()))\n",
    "print(\"Standard deviation:\", standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standardizing Using the Meadian and IQR</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:04:46.493633Z",
     "start_time": "2020-02-09T21:04:46.480702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Create function\n",
    "x = np.array([[-1000.1],\n",
    "             [-200.2],\n",
    "             [500.5],\n",
    "             [600.6],\n",
    "             [9000.9]])\n",
    "\n",
    "#Create scaler\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "#Transform feature\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Normalizing Observations</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two common types of norms are 'l1' or Manhatten, and 'l2' or Euclidean. The Euclidean norm is calculated as the abs(x) = sqrt(x1^2 + x2^2 + ... + xn^2). The Manhatten norm is calculated as the abs(x) = sum of all abs(x) values. Manhattan norm rescales an observation's values so they sum to 1. Euclidean is the distance between two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:09:15.626327Z",
     "start_time": "2020-02-09T21:09:15.615388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Create feature matrix\n",
    "features = np.array([[0.5, 0.5],\n",
    "                    [1.1, 3.4],\n",
    "                    [1.5, 20.2],\n",
    "                    [1.63, 34.4],\n",
    "                    [10.9, 3.3]])\n",
    "\n",
    "#Create l2 normalizer\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "\n",
    "#Transform feature matrix\n",
    "features_l2_norm = normalizer.transform(features)\n",
    "\n",
    "#Show feature matrix\n",
    "features_l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:12:43.317290Z",
     "start_time": "2020-02-09T21:12:43.310301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create l1 normalizer\n",
    "normalizer = Normalizer(norm=\"l1\")\n",
    "\n",
    "#Transform feature matrix\n",
    "features_l1_norm = normalizer.transform(features)\n",
    "\n",
    "#Show feature matrix\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:13:47.477077Z",
     "start_time": "2020-02-09T21:13:47.471097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of the first observations's values: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Print sum\n",
    "print(\"Sum of the first observations\\'s values:\",\n",
    "     features_l1_norm[0, 0] + features_l1_norm[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generating Polynomial and Interaction Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:35:15.768076Z",
     "start_time": "2020-02-09T21:35:15.759100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "                    [2, 3],\n",
    "                    [2, 3]])\n",
    "\n",
    "#Create Polynomial object\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "#Create polynomialfeatures\n",
    "polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:37:07.707310Z",
     "start_time": "2020-02-09T21:37:07.700330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restrict features to only interaction features\n",
    "interaction = PolynomialFeatures(degree=2,\n",
    "                                interaction_only=True, include_bias=False)\n",
    "\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Transforming Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:40:13.714341Z",
     "start_time": "2020-02-09T21:40:13.691429Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:98: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "                    [2, 3],\n",
    "                    [2, 3]])\n",
    "\n",
    "#Define a simple function\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "\n",
    "#Create transformer\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "#Transform feature matrix\n",
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:41:20.830909Z",
     "start_time": "2020-02-09T21:41:20.787028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can do the same thing using pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Create DataFrame\n",
    "df = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "#Apply function\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Detecting Outliers</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using Ellipse</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:45:09.375523Z",
     "start_time": "2020-02-09T21:45:09.196306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Detecting outliers by drawing an ellipse around the data assuming a normal distribution\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "#Create simulated data\n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "                        n_features = 2,\n",
    "                        centers = 1,\n",
    "                        random_state = 42)\n",
    "\n",
    "#Replace the first observation's values with extreme values\n",
    "features[0, 0] = 10000\n",
    "features[0, 1] = 10000\n",
    "\n",
    "#Create detector, contamination is the % of data that are outliers\n",
    "outlier_detector = EllipticEnvelope(contamination = .1)\n",
    "\n",
    "#Fit detector\n",
    "outlier_detector.fit(features)\n",
    "\n",
    "#Predict outliers\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using IQR and Looking at Individual Features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:51:16.902791Z",
     "start_time": "2020-02-09T21:51:16.889827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "#Create simulated data\n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "                        n_features = 2,\n",
    "                        centers = 1,\n",
    "                        random_state = 42)\n",
    "\n",
    "#Replace the first observation's values with extreme values\n",
    "features[0, 0] = 10000\n",
    "features[0, 1] = 10000\n",
    "\n",
    "#Create one feature\n",
    "feature = features[:,0]\n",
    "\n",
    "#Create a function to return index of outliers\n",
    "def indicies_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((x > upper_bound) | (x < lower_bound))\n",
    "\n",
    "#Run function\n",
    "indicies_of_outliers(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:51:39.785507Z",
     "start_time": "2020-02-09T21:51:39.778526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show extreme values\n",
    "feature[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Using Z-score Method</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:56:43.354071Z",
     "start_time": "2020-02-09T21:56:43.338157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "#Create simulated data\n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "                        n_features = 2,\n",
    "                        centers = 1,\n",
    "                        random_state = 42)\n",
    "\n",
    "#Replace the first observation's values with extreme values\n",
    "features[0, 0] = 10000\n",
    "features[0, 1] = 10000\n",
    "\n",
    "#Create one feature\n",
    "feature = features[:,0]\n",
    "\n",
    "#Create a function to return index of outliers\n",
    "def outliers_z_score(x):\n",
    "    threshold = 3\n",
    "    \n",
    "    mean_x = np.mean(x)\n",
    "    stddev_x = np.std(x)\n",
    "    z_scores = [(i - mean_x) / stddev_x for i in x]\n",
    "    return np.where(np.abs(z_scores) >  threshold)\n",
    "\n",
    "#Run function\n",
    "outliers_z_score(feature)\n",
    "\n",
    "#No feature detected because the outlier is influencing the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T21:59:58.502476Z",
     "start_time": "2020-02-09T21:59:58.492506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Z-score method with median to make it more robust\n",
    "\n",
    "def outliers_modified_z_score(x):\n",
    "    threshold = 3\n",
    "    \n",
    "    median_x = np.median(x)\n",
    "    median_absolute_deviation_x = np.median([np.abs(i - median_x) for i in x])\n",
    "    modified_z_scores = [0.6745 * (i - median_x) / median_absolute_deviation_x for i in x]\n",
    "    \n",
    "    return np.where(np.abs(modified_z_scores) > threshold)\n",
    "\n",
    "#Run funcction\n",
    "outliers_modified_z_score(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:00:13.609991Z",
     "start_time": "2020-02-09T22:00:13.603009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show extreme values\n",
    "feature[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:00:42.120218Z",
     "start_time": "2020-02-09T22:00:42.113241Z"
    }
   },
   "source": [
    "<h3>Handling Outliers</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Option 1: Drop Outliers</h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:02:56.512792Z",
     "start_time": "2020-02-09T22:02:56.495814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53433</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bathrooms  Square_Feet\n",
       "0   53433          2         1500\n",
       "1  392333          3         2500\n",
       "2  293222          2         1500"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create DataFrame\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [53433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000]\n",
    "\n",
    "#Filter observations\n",
    "houses[houses['Bathrooms'] < 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Option 2: Mark Outliers and Include as a Feature</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:04:24.812920Z",
     "start_time": "2020-02-09T22:04:24.799979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53433</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier\n",
       "0    53433          2         1500        0\n",
       "1   392333          3         2500        0\n",
       "2   293222          2         1500        0\n",
       "3  4322032        116        48000        1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Create feature based on boolean condition\n",
    "houses['Outlier'] = np.where(houses['Bathrooms'] < 20, 0, 1)\n",
    "\n",
    "#Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Option 3: Transform the Feature to Dampen the Effect of Outliers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:06:22.350528Z",
     "start_time": "2020-02-09T22:06:22.339557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>Log_of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53433</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.778956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier  Log_of_Square_Feet\n",
       "0    53433          2         1500        0            7.313220\n",
       "1   392333          3         2500        0            7.824046\n",
       "2   293222          2         1500        0            7.313220\n",
       "3  4322032        116        48000        1           10.778956"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Log feature\n",
    "houses[\"Log_of_Square_Feet\"] = [np.log(x) for x in houses[\"Square_Feet\"]]\n",
    "\n",
    "#Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Discretizating Features</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a numerical feature and want to break it up into discrete bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:09:00.945777Z",
     "start_time": "2020-02-09T22:09:00.935804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#Create feature\n",
    "age = np.array([[6],\n",
    "               [12],\n",
    "               [20],\n",
    "               [36],\n",
    "               [65]])\n",
    "\n",
    "#Create binarizer\n",
    "binarizer = Binarizer(18)\n",
    "\n",
    "#Transform feature\n",
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:10:25.560339Z",
     "start_time": "2020-02-09T22:10:25.554390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bin feature based on multiple thresholds, does not include the threshold value unless you mark right=True\n",
    "np.digitize(age, bins=[20, 30, 64], right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grouping Observations Using Clustering</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:13:34.983617Z",
     "start_time": "2020-02-09T22:13:34.855948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_!</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_!  feature_2  group\n",
       "0  -9.877554  -3.336145      0\n",
       "1  -7.287210  -8.353986      2\n",
       "2  -6.943061  -7.023744      2\n",
       "3  -7.440167  -8.791959      2\n",
       "4  -6.641388  -8.075888      2"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Make simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 50,\n",
    "                        n_features = 2,\n",
    "                        centers = 3,\n",
    "                        random_state = 1)\n",
    "\n",
    "#Create DataFrame\n",
    "dataframe = pd.DataFrame(features, columns=['feature_!', 'feature_2'])\n",
    "\n",
    "#Make k-means clusterer\n",
    "clusterer = KMeans(3, random_state = 42)\n",
    "\n",
    "#Fit clusterer\n",
    "clusterer.fit(features)\n",
    "\n",
    "#Predict values\n",
    "dataframe[\"group\"] = clusterer.predict(features)\n",
    "\n",
    "#View first few observations\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deleting Observations with Missing Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:15:26.281030Z",
     "start_time": "2020-02-09T22:15:26.271056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Crate feature matrix\n",
    "features = np.array([[1.1, 11.1],\n",
    "                    [2.2, 22.2],\n",
    "                    [3.3, 33.3],\n",
    "                    [4.4, 44.4],\n",
    "                    [np.nan, 55]])\n",
    "\n",
    "#Keep only observations that are not (denoted by ~) missing\n",
    "features[~np.isnan(features).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:16:34.445010Z",
     "start_time": "2020-02-09T22:16:34.434074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can also drop observations using pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Load data\n",
    "dataframe = pd.DataFrame(features, columns=['feature_1', 'feature_2'])\n",
    "\n",
    "#Remove observations with missing values\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imputing Missing Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Impute based on k-nearest neighbors</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:34:45.404767Z",
     "start_time": "2020-02-09T22:34:45.213178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.8730186113995938\n",
      "Imputed Value: 1.0955332713113226\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "#Make a simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "                        n_features = 2,\n",
    "                        random_state = 1)\n",
    "\n",
    "#Standardize the features\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "#Replace the first feature's first value with a missing value\n",
    "true_value = standardized_features[0, 0]\n",
    "standardized_features[0, 0] = np.nan\n",
    "\n",
    "#Predict the missing values in the feature matrix\n",
    "features_knn_imputed = KNN(k=5, verbose=0).fit_transform(standardized_features)\n",
    "\n",
    "#Comapre true and imputed values\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_knn_imputed[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Impute using mean, median, or most frequent value</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:36:27.052633Z",
     "start_time": "2020-02-09T22:36:27.038671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.8730186113995938\n",
      "Imputed Value: -3.058372724614996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Create imputer\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "#Impute values\n",
    "features_mean_imputed = mean_imputer.fit_transform(features)\n",
    "\n",
    "#Compare true and imputed values\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_mean_imputed[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T22:37:09.995015Z",
     "start_time": "2020-02-09T22:37:09.989033Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Handling Categorical Data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding Nominal Categorical Features Using One-Hot Encoding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:46:52.036481Z",
     "start_time": "2020-02-09T23:46:52.018527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "#Create feature\n",
    "feature = np.array([[\"Texas\"],\n",
    "                   [\"California\"],\n",
    "                   [\"Texas\"],\n",
    "                   [\"Delaware\"],\n",
    "                   [\"Texas\"]])\n",
    "\n",
    "#Create one-hot encoder\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "#One-hot encode feature\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:47:07.663471Z",
     "start_time": "2020-02-09T23:47:07.657487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View feature classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:47:35.690127Z",
     "start_time": "2020-02-09T23:47:35.683147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reverse one-hot encoding\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:48:25.881908Z",
     "start_time": "2020-02-09T23:48:25.850966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using pandas to one-hot encode features\n",
    "import pandas as pd\n",
    "\n",
    "#Create dummy variables from feature\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:50:50.210493Z",
     "start_time": "2020-02-09T23:50:50.202489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create multiclass feature\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"),\n",
    "                     (\"California\", \"Alabama\"),\n",
    "                     (\"Texas\", \"Florida\"),\n",
    "                     (\"Delware\", \"Florida\"),\n",
    "                     (\"Texas\", \"Alabama\")]\n",
    "\n",
    "#Create multiclass one-hot encoder\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "\n",
    "#One-hot encode multiclass feature\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:51:19.357922Z",
     "start_time": "2020-02-09T23:51:19.352932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delware', 'Florida', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View classes\n",
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding Ordinal Categorical Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:53:59.063481Z",
     "start_time": "2020-02-09T23:53:59.051514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create features\n",
    "dataframe = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
    "\n",
    "#Create mapper\n",
    "scale_mapper = {\"Low\": 1,\n",
    "               \"Medium\": 2,\n",
    "               \"High\": 3}\n",
    "\n",
    "#Replace feature values with scale\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-09T23:56:34.941229Z",
     "start_time": "2020-02-09T23:56:34.930257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    4\n",
       "5    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another example\n",
    "dataframe = pd.DataFrame({\"Score\": [\"Low\",\n",
    "                                   \"Low\",\n",
    "                                   \"Medium\",\n",
    "                                   \"Medium\",\n",
    "                                   \"High\",\n",
    "                                   \"Barely More Than Medium\"]})\n",
    "\n",
    "scale_mapper = {\"Low\": 1,\n",
    "               \"Medium\": 2,\n",
    "               \"Barely More Than Medium\": 3,\n",
    "               \"High\": 4}\n",
    "\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding Dictionaries of Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T00:00:45.413636Z",
     "start_time": "2020-02-10T00:00:45.402659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#Create dictionary\n",
    "data_dict = [{\"Red\": 2, \"Blue\": 4},\n",
    "            {\"Red\": 4, \"Blue\": 3},\n",
    "            {\"Red\": 1, \"Yellow\": 2},\n",
    "            {\"Red\": 2, \"Yellow\": 2}]\n",
    "\n",
    "#Create dictionary vectorizer\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "#Convert dictionary to feature matrix\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "#View feature matrix\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T00:01:35.571029Z",
     "start_time": "2020-02-10T00:01:35.565076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blue', 'Red', 'Yellow']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get feature names\n",
    "feature_names = dictvectorizer.get_feature_names()\n",
    "\n",
    "#View feature names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T00:02:06.550170Z",
     "start_time": "2020-02-10T00:02:06.540196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Red</th>\n",
       "      <th>Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Red  Yellow\n",
       "0   4.0  2.0     0.0\n",
       "1   3.0  4.0     0.0\n",
       "2   0.0  1.0     2.0\n",
       "3   0.0  2.0     2.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create dataframe from features\n",
    "pd.DataFrame(features, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imputing Missing Class Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Option 1: K-NN</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T03:50:50.324093Z",
     "start_time": "2020-02-10T03:50:50.297143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create feature matrix with categorical feature\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "             [1, 1.18, 1.33],\n",
    "             [0, 1.22, 1.27],\n",
    "             [1, -0.21, -1.19]])\n",
    "\n",
    "#Create feature matrix with missing values in the categorical feature\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                      [np.nan, -0.67, -0.22]])\n",
    "\n",
    "#Train KNN Learner\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "#Predict missing values' class\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
    "\n",
    "#Join column of predicted class with their other features\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "\n",
    "#Join two feature matrices\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Option 2: Most Frequent</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T03:55:42.269296Z",
     "start_time": "2020-02-10T03:55:42.255332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Join the two feature matrices\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Handling Imbalanced Classes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Option 1: Use Algorithm Option to Weight Classes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:02:37.768276Z",
     "start_time": "2020-02-10T04:02:37.712428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#Load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "#Create feature and target vectors\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "#Remove first 40 observations to make imbalanced classes\n",
    "features = features[40:]\n",
    "target = target[40:]\n",
    "\n",
    "#Create binary target vector indicating if class O\n",
    "target = np.where((target == 0), 0, 1)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:04:22.750572Z",
     "start_time": "2020-02-10T04:04:22.742561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.9, 1: 0.1}, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can specify class weights explicitly\n",
    "#Create weights\n",
    "weights = {0: .9, 1: 0.1}\n",
    "\n",
    "#Create random forest classifier with weights\n",
    "RandomForestClassifier(class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:05:44.934779Z",
     "start_time": "2020-02-10T04:05:44.927829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can also pass 'balanced' to to automatically create weights inversely proportional to class frequencies\n",
    "#Train a random forest with balanced class weights\n",
    "RandomForestClassifier(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Downsampling Majority Class</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:09:03.792927Z",
     "start_time": "2020-02-10T04:09:03.780954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Indicies of each class' observations\n",
    "i_class0 = np.where(target == 0)[0]\n",
    "i_class1 = np.where(target == 1)[0]\n",
    "\n",
    "#Number of observations in each class\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "#For every observation of class 0, randomly sample from class 1 without replacement\n",
    "i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "\n",
    "#Joing together class 0's target vector with the downsampled class 1's target vector\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:10:07.806209Z",
     "start_time": "2020-02-10T04:10:07.799228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join together class 0's feature matric with the downsampled class 1's feature matrix\n",
    "np.vstack((features[i_class0,:], features[i_class1_downsampled,:]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Upsampling Minority Class</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:12:28.064089Z",
     "start_time": "2020-02-10T04:12:28.054119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For every observation in class 1, randomly sample from class 0 with replacement\n",
    "i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True)\n",
    "\n",
    "#Join together class 0's upsampled target vector with class 1's target vector\n",
    "np.concatenate((target[i_class0_upsampled], target[i_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:13:29.182170Z",
     "start_time": "2020-02-10T04:13:29.174196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join together class 0's upsampled feature matrix with class 1's feature matrix\n",
    "np.vstack((features[i_class0_upsampled,:], features[i_class1,:]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Handling Text</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cleaning Text</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:17:15.351517Z",
     "start_time": "2020-02-10T04:17:15.345515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang. By Alshwarya Henriette',\n",
       " 'Parking And Going. By Karl Gautier',\n",
       " 'Today Is The Night. By Jarek Prakash']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create text\n",
    "text_data = [\"     Interrobang. By Alshwarya Henriette      \",\n",
    "            \"Parking And Going. By Karl Gautier\",\n",
    "            \"     Today Is The Night. By Jarek Prakash    \"]\n",
    "\n",
    "#Strip whitespace\n",
    "strip_whitespace = [string.strip() for string in text_data]\n",
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:19:22.284569Z",
     "start_time": "2020-02-10T04:19:22.277589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang By Alshwarya Henriette',\n",
       " 'Parking And Going By Karl Gautier',\n",
       " 'Today Is The Night By Jarek Prakash']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove periods\n",
    "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
    "remove_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:19:23.859581Z",
     "start_time": "2020-02-10T04:19:23.853597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTERROBANG BY ALSHWARYA HENRIETTE',\n",
       " 'PARKING AND GOING BY KARL GAUTIER',\n",
       " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create function\n",
    "def capitalizer(string: str) -> str:\n",
    "    return string.upper()\n",
    "\n",
    "#Apply function\n",
    "[capitalizer(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:20:55.814921Z",
     "start_time": "2020-02-10T04:20:55.806941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
       " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
       " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#Create function\n",
    "def replace_letters_with_X(string: str) -> str:\n",
    "    return re.sub(r\"[a-zA-Z]\", \"X\", string)\n",
    "\n",
    "#Apply function\n",
    "[replace_letters_with_X(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Parsing and Cleaning HTML</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:26:46.570063Z",
     "start_time": "2020-02-10T04:26:46.559095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Masego Azra'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Create some HTML code\n",
    "html = \"<div class='full_name'><span style='font-weight:bold'>Masego</span> Azra</div>\"\n",
    "\n",
    "#Parse HTML\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "#Find the div with the class \"full_name\", show text\n",
    "soup.find(\"div\", {\"class\": \"full_name\"}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Removing Punctuation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:30:21.733527Z",
     "start_time": "2020-02-10T04:30:21.268731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "#Create text\n",
    "text_data = ['Hi!!!! I. Love. This. Song....',\n",
    "            '10000% Agree!!!! #LoveIT',\n",
    "            'Right?!?!']\n",
    "\n",
    "#Create dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "#For each string, remove any punctuation characters\n",
    "[string.translate(punctuation) for string in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tokenizing Text</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:32:06.580737Z",
     "start_time": "2020-02-10T04:32:06.562785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Create text\n",
    "string = \"The science of today is the technology of tomorrow\"\n",
    "\n",
    "#Tokenize words\n",
    "word_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:33:23.070281Z",
     "start_time": "2020-02-10T04:33:23.061306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can also tokenize into sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#Create text\n",
    "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
    "\n",
    "#Tokenize sentences\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Removing Stop Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:35:54.569787Z",
     "start_time": "2020-02-10T04:35:54.551835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nhundley\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Create word tokens\n",
    "tokenized_words = ['i',\n",
    "                  'am',\n",
    "                  'going',\n",
    "                  'to',\n",
    "                  'go',\n",
    "                  'to',\n",
    "                  'the',\n",
    "                  'store',\n",
    "                  'and',\n",
    "                  'park']\n",
    "\n",
    "#Load stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#Remove stop words\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Stemming Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:37:47.361351Z",
     "start_time": "2020-02-10T04:37:47.352376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#Create word tokens\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "\n",
    "#Create stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "#Apply stemmer\n",
    "[porter.stem(word) for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tagging Parts of Speech</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:39:20.639163Z",
     "start_time": "2020-02-10T04:39:20.507515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#Create text\n",
    "text_data = \"Chris loved outdoor running\"\n",
    "\n",
    "#Use pretrained part of speech tagger\n",
    "text_tagged = pos_tag(word_tokenize(text_data))\n",
    "\n",
    "#Show parts of speech\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:40:35.692966Z",
     "start_time": "2020-02-10T04:40:35.686984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chris']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter words to find all nouns\n",
    "[word for word, tag in text_tagged if tag in ['NN', 'NNS', 'NNP', 'NNPS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:45:10.280824Z",
     "start_time": "2020-02-10T04:45:10.264866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting sentences into features for individual parts of speech\n",
    "#Feature is 1 if a proper noun is present, and 0 otherwise\n",
    "\n",
    "#Create text\n",
    "tweets = ['I am eating a burrito for breakfast',\n",
    "         'Political science is an amazing field',\n",
    "         'San Francisco is an awesome city']\n",
    "\n",
    "#Create list\n",
    "tagged_tweets = []\n",
    "\n",
    "#Tag eacg word and each tweet\n",
    "for tweet in tweets:\n",
    "    tweet_tag = nltk.pos_tag(word_tokenize(tweet))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])\n",
    "\n",
    "#Use one-hot encoding to convert the tags into features\n",
    "one_hot_multi = MultiLabelBinarizer()\n",
    "one_hot_multi.fit_transform(tagged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:45:28.500752Z",
     "start_time": "2020-02-10T04:45:28.495764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DT', 'IN', 'JJ', 'NN', 'NNP', 'PRP', 'VBG', 'VBP', 'VBZ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show feature names\n",
    "one_hot_multi.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train PoS Tagger</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:49:37.826857Z",
     "start_time": "2020-02-10T04:49:34.766475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8174734002697437"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "\n",
    "#Get some text from the Brown Corpus, broken into sentences\n",
    "sentences = brown.tagged_sents(categories = 'news')\n",
    "\n",
    "#Split into 4000 sentences for training and 623 for testing\n",
    "train = sentences[:4000]\n",
    "test = sentences[4000:]\n",
    "\n",
    "#Create backoff tagger\n",
    "unigram = UnigramTagger(train)\n",
    "bigram = BigramTagger(train, backoff=unigram)\n",
    "trigram = TrigramTagger(train, backoff=bigram)\n",
    "\n",
    "#Show accuracy\n",
    "trigram.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding Text as a Bag of Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:51:36.642490Z",
     "start_time": "2020-02-10T04:51:36.633517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                     'Sweden is best',\n",
    "                     'Germany beats both'])\n",
    "\n",
    "#Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "#Show feature matrix\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:51:56.692275Z",
     "start_time": "2020-02-10T04:51:56.687286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:52:13.368874Z",
     "start_time": "2020-02-10T04:52:13.361893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love', 'sweden']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show feature names\n",
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:54:22.258635Z",
     "start_time": "2020-02-10T04:54:22.250659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Custom bag of words\n",
    "#Create feature matrix with arguments\n",
    "count_2gram = CountVectorizer(ngram_range=(1,2),\n",
    "                             stop_words='english',\n",
    "                             vocabulary=['brazil'])\n",
    "\n",
    "bag = count_2gram.fit_transform(text_data)\n",
    "\n",
    "#View feature matrix\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:54:45.008862Z",
     "start_time": "2020-02-10T04:54:45.002873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazil': 0}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the 1-grams and 2-grams\n",
    "count_2gram.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Weighting Word Importance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:56:57.581513Z",
     "start_time": "2020-02-10T04:56:57.569539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                     'Sweden is best',\n",
    "                     'Germany beats both!'])\n",
    "\n",
    "#Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "\n",
    "#Show tf-idf feature matrix\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:57:28.729211Z",
     "start_time": "2020-02-10T04:57:28.723233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show tf-idf feature matrix as dense matrix\n",
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:57:46.128703Z",
     "start_time": "2020-02-10T04:57:46.122721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show feature names\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Dimensionality Reduction Using Feature Extraction</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reducing Features Using Principal Components</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T06:53:16.720143Z",
     "start_time": "2020-02-10T06:53:16.560193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load the data\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#Standardize the feature matrix\n",
    "features = StandardScaler().fit_transform(digits.data)\n",
    "\n",
    "#Create a PCA that will retain 99% of variance\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "\n",
    "#Conduct PCA\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "#Show results\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reducing Features When Data is Linearly Inseparable</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T06:57:27.358730Z",
     "start_time": "2020-02-10T06:57:27.294898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 2\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "#Create linearly inseparable data\n",
    "features, _ = make_circles(n_samples=1000, random_state=42, noise=0.1, factor=0.1)\n",
    "\n",
    "#Apply kernel PCA with radius basis function (RBF) kernel\n",
    "kpca = KernelPCA(kernel='rbf', gamma=15, n_components=1)\n",
    "features_kpca = kpca.fit_transform(features)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kpca.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T13:52:38.080935Z",
     "start_time": "2020-05-12T13:52:38.067963Z"
    }
   },
   "source": [
    "<h3>Reducing Features by Maximizing Class Separability</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T13:56:15.316580Z",
     "start_time": "2020-05-12T13:56:15.304615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#Load Iris flower dataset\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#Create and run an LDA, then use it to transform the features\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "features_lda = lda.fit(features, target).transform(features)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_lda.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T13:56:50.472138Z",
     "start_time": "2020-05-12T13:56:50.462165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9912126])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explained variance by each component\n",
    "lda.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:03:48.038616Z",
     "start_time": "2020-05-12T14:03:48.024654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function to return the ratio of variance explained by each component, \n",
    "# then calculating how many components are required to get above some threhold of variance explained\n",
    "\n",
    "#Create and run LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=None)\n",
    "features_lda = lda.fit(features, target)\n",
    "\n",
    "#Create array of explained variance ratios\n",
    "lda_var_ratios = lda.explained_variance_ratio_\n",
    "\n",
    "#Create function\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    #Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    #Set initial number of components/features\n",
    "    n_components = 0\n",
    "    \n",
    "    #For the explained variance of each component\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        #Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        #Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        #If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            #End the loop\n",
    "            break\n",
    "        \n",
    "    #Return the number of components\n",
    "    return n_components\n",
    "\n",
    "#Run function\n",
    "select_n_components(lda_var_ratios, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reducing Features Using Matrix Factorization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:06:56.665742Z",
     "start_time": "2020-05-12T14:06:56.349667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load the data\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#Load feature matrix\n",
    "features = digits.data\n",
    "\n",
    "#Create, fit, and apply NMF\n",
    "nmf = NMF(n_components=10, random_state=1)\n",
    "features_nmf = nmf.fit_transform(features)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_nmf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reducing Features on Sparse Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:12:00.268739Z",
     "start_time": "2020-05-12T14:12:00.119143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 64\n",
      "Reduced number of features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "#Load the data\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#Standardize feature matrix\n",
    "features = StandardScaler().fit_transform(digits.data)\n",
    "\n",
    "#Make sparse matrix\n",
    "features_sparse = csr_matrix(features)\n",
    "\n",
    "#Create a TSVD\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "\n",
    "#Conduct the TSVD on sparse matrix\n",
    "features_sparse_tsvd = tsvd.fit(features_sparse).transform(features_sparse)\n",
    "\n",
    "print(\"Original number of features:\", features_sparse.shape[1])\n",
    "print(\"Reduced number of features:\", features_sparse_tsvd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:14:18.999875Z",
     "start_time": "2020-05-12T14:14:18.992894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3003938536317932"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sum of first three components' explained variance ratios\n",
    "tsvd.explained_variance_ratio_[0:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:19:54.940705Z",
     "start_time": "2020-05-12T14:19:54.870892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function that runs TSVD with n_components set to one less than the number of original features and then\n",
    "# calculate the number of components that explain a desired amount of the original data's variance\n",
    "\n",
    "#Create and run an TSVD with one less than number of features\n",
    "tsvd = TruncatedSVD(n_components=features_sparse.shape[1]-1)\n",
    "features_tsvd = tsvd.fit(features)\n",
    "\n",
    "#List of explained variances\n",
    "tsvd_var_ratios = tsvd.explained_variance_ratio_\n",
    "\n",
    "#Create a function\n",
    "def select_n_components(var_ratio, goal_var):\n",
    "    #Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    #Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    #For the explained variance of each feature\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        #Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        #Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        #If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            #End the loop\n",
    "            break\n",
    "    \n",
    "    #Return the number of components\n",
    "    return n_components\n",
    "\n",
    "#Run funciton\n",
    "select_n_components(tsvd_var_ratios, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:20:28.309345Z",
     "start_time": "2020-05-12T14:20:28.304363Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Dimensionality Reduction Using Feature Selection</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Thresholding Numerical Feature Variance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:25:02.551099Z",
     "start_time": "2020-05-12T14:25:02.479290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#Import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#Create fatures and target\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#Create thresholder\n",
    "thresholder = VarianceThreshold(threshold=.5)\n",
    "\n",
    "#Create high variance feature matrix\n",
    "features_high_variance = thresholder.fit_transform(features)\n",
    "\n",
    "#View high variance feature matrix\n",
    "features_high_variance[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:25:57.569908Z",
     "start_time": "2020-05-12T14:25:57.561937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68112222, 0.18871289, 3.09550267, 0.57713289])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View variances\n",
    "thresholder.fit(features).variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Thresholding Binary Feature Variance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:29:36.464894Z",
     "start_time": "2020-05-12T14:29:36.455944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#Create feature matrix with:\n",
    "# Feature 0: 80% class 0\n",
    "# Feature 1: 80% class 1\n",
    "# Feature 2: 60% class 0, 40% class 1\n",
    "features = [[0, 1, 0],\n",
    "           [0, 1, 1],\n",
    "           [0, 1, 0],\n",
    "           [0, 1, 1],\n",
    "           [1, 0, 0]]\n",
    "\n",
    "#Run threshold by variance\n",
    "thresholder = VarianceThreshold(threshold=(.75 * (1 - .75)))\n",
    "thresholder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Handling Highly Correlated Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:34:34.274731Z",
     "start_time": "2020-05-12T14:34:32.940302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  2\n",
       "0  1  1\n",
       "1  2  0\n",
       "2  3  1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Create feature matrix with two highly correlated features\n",
    "features = np.array([[1, 1, 1],\n",
    "                    [2, 2, 0],\n",
    "                    [3, 3, 1],\n",
    "                    [4, 4, 0],\n",
    "                    [5, 5, 1],\n",
    "                    [6, 6, 0],\n",
    "                    [7, 7, 1],\n",
    "                    [8, 7, 0],\n",
    "                    [9, 7, 1]])\n",
    "\n",
    "#Convert feature matrix into DataFrame\n",
    "dataframe = pd.DataFrame(features)\n",
    "\n",
    "#Create correlation matrix\n",
    "corr_matrix = dataframe.corr().abs()\n",
    "\n",
    "#Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),\n",
    "                                 k=1).astype(np.bool))\n",
    "\n",
    "#Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "#Drop features\n",
    "dataframe.drop(dataframe.columns[to_drop], axis=1).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:36:29.567167Z",
     "start_time": "2020-05-12T14:36:29.554202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.976103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034503</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.976103  0.000000\n",
       "1  0.976103  1.000000 -0.034503\n",
       "2  0.000000 -0.034503  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation matrix\n",
    "dataframe.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Removing Irrelevant Features for Classification</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:47:07.856002Z",
     "start_time": "2020-05-12T14:47:07.834061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "#Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#Convert to categorical data by converting data to integers\n",
    "features = features.astype(int)\n",
    "\n",
    "#Select two features with highest chi-squared statistics\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:49:33.770410Z",
     "start_time": "2020-05-12T14:49:33.761437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# For quantitative features, compute ANOVA F-value betweene ach feature and the target vector\n",
    "\n",
    "#Select two features with highest F-values\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T14:51:57.707138Z",
     "start_time": "2020-05-12T14:51:57.699157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 3\n"
     ]
    }
   ],
   "source": [
    "# We can also select the top n percent of features\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "#Select the top 75% of features with highest F=va;ies\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recursively Eliminating Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:38:47.389557Z",
     "start_time": "2020-05-12T15:38:37.027088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00850799,  0.7031277 , -0.34606121],\n",
       "       [-1.07500204,  2.56148527, -1.8392567 ],\n",
       "       [ 1.37940721, -1.77039484, -0.90016708],\n",
       "       ...,\n",
       "       [-0.80331656, -1.60648007, -1.28329706],\n",
       "       [ 0.39508844, -1.34564911,  0.85012142],\n",
       "       [-0.55383035,  0.82880112,  0.27741159]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "#Suppress an annoying but harmless warning\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"internal gelsd\")\n",
    "\n",
    "#Generate feature matrix, target vector, and the true coefficients\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                  n_features = 100,\n",
    "                                  n_informative = 2,\n",
    "                                  random_state =1)\n",
    "\n",
    "#Create linear regression\n",
    "ols = linear_model.LinearRegression()\n",
    "\n",
    "#Recursively eliminate features\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:39:06.977779Z",
     "start_time": "2020-05-12T15:39:06.971794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of best features\n",
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:39:43.730066Z",
     "start_time": "2020-05-12T15:39:43.725079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which categories are best\n",
    "rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:40:13.565613Z",
     "start_time": "2020-05-12T15:40:13.557633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 47, 66, 74, 28,  1, 33, 36, 39, 35, 41, 45,  5, 32, 30, 51, 42,\n",
       "       88, 10, 27, 82, 84, 54, 95, 24, 98, 73, 20, 13, 59, 40, 76, 26,  9,\n",
       "       17, 21, 65, 75, 57,  1, 14, 38, 64, 96, 19, 78,  2, 37, 90, 89, 93,\n",
       "       12, 25, 58, 29, 97, 22,  7, 83, 48,  4, 15, 77,  6, 46, 67, 87, 80,\n",
       "       53, 49, 86, 60, 68, 62, 79, 34,  3, 31,  1, 69, 44, 72,  8, 71, 85,\n",
       "       81, 11, 55, 94, 56, 52, 18, 43, 61, 16, 70, 91, 23, 92, 63])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rank features best (1) to worst\n",
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T15:41:39.077078Z",
     "start_time": "2020-05-12T15:41:39.070098Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Model Evaluation</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross-Validating Models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:35:38.992193Z",
     "start_time": "2020-05-12T16:35:36.359222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Load digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#Create features matrix\n",
    "features = digits.data\n",
    "\n",
    "#Create target vector\n",
    "target = digits.target\n",
    "\n",
    "#Create standadizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "#Create logistic regression object\n",
    "logit = LogisticRegression()\n",
    "\n",
    "#Create a pipeline that standardizes, then runs logisitc regression\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "#Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "#Conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, #Pipeline\n",
    "                            features, #Feature matrix\n",
    "                            target, #Target vector\n",
    "                            cv=kf, #Cross-validation technique\n",
    "                            scoring=\"accuracy\", #Loss function\n",
    "                            n_jobs=-1) #Use all CPU cores\n",
    "\n",
    "#Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:36:30.133898Z",
     "start_time": "2020-05-12T16:36:30.126918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View score for all 10 folds\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:42:39.482336Z",
     "start_time": "2020-05-12T16:42:38.865348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratified K-Fold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Creating training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "#Fit standardizer to training set\n",
    "standardizer.fit(features_train)\n",
    "\n",
    "#Apply to both training and test sets\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)\n",
    "\n",
    "#Create a pipeline\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "#Do k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, #Pipeline\n",
    "                            features, #Feature matrix\n",
    "                            target, #Target vector\n",
    "                            cv=kf, #Cross-validation technique\n",
    "                            scoring=\"accuracy\", #Loss function\n",
    "                            n_jobs=-1) #Use all CPU cores\n",
    "\n",
    "#Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Baseline Regression Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:46:00.893198Z",
     "start_time": "2020-05-12T16:46:00.864241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load data\n",
    "boston = load_boston()\n",
    "\n",
    "#Create features\n",
    "features, target = boston.data, boston.target\n",
    "\n",
    "#Make test and training split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "#Create a dummy regressor\n",
    "dummy = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "#\"Train\" dummy regressor\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "#Get R-squared score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:49:06.425396Z",
     "start_time": "2020-05-12T16:49:06.416419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06510502029325727"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dummy regressor that predicts 20's for everything\n",
    "clf = DummyRegressor(strategy=\"constant\", constant=20)\n",
    "clf.fit(features_train, target_train)\n",
    "\n",
    "#Evaluate score\n",
    "clf.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:47:17.822002Z",
     "start_time": "2020-05-12T16:47:17.810036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690382480076236"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Train simple linear regression model\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_test, target_test)\n",
    "\n",
    "#Get R-squared score\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Baseline Classification Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:54:15.772959Z",
     "start_time": "2020-05-12T16:54:15.755008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load data\n",
    "iris = load_iris()\n",
    "\n",
    "#Create target vector and feature matrix\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "#Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "#Create dummy classifier\n",
    "dummy = DummyClassifier(strategy=\"uniform\", random_state=1)\n",
    "\n",
    "#'Train' model\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "#Get accuracy score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T16:57:16.625468Z",
     "start_time": "2020-05-12T16:57:16.403683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "#Train model\n",
    "classifier.fit(features_train, target_train)\n",
    "\n",
    "#Get accuracy score\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Binary Classifier Predictions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:02:18.006101Z",
     "start_time": "2020-05-12T17:02:17.912472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9550999999999998"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#Generate features matrix and target vector\n",
    "X, y = make_classification(n_samples = 10000,\n",
    "                          n_features = 3,\n",
    "                          n_informative = 3,\n",
    "                          n_redundant = 0,\n",
    "                          n_classes = 2,\n",
    "                          random_state = 1)\n",
    "\n",
    "#Create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "#Cross-vaidate model using accuracy\n",
    "cross_val_score(logit, X, y, scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:02:13.027847Z",
     "start_time": "2020-05-12T17:02:12.946029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587098102922853"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-vaidate model using precision\n",
    "cross_val_score(logit, X, y, scoring=\"precision\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:03:06.692894Z",
     "start_time": "2020-05-12T17:03:06.616099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511999999999998"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-vaidate model using recall\n",
    "cross_val_score(logit, X, y, scoring=\"recall\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:03:45.158273Z",
     "start_time": "2020-05-12T17:03:45.069506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954931376985931"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-vaidate model using F1\n",
    "cross_val_score(logit, X, y, scoring=\"f1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:14:17.945503Z",
     "start_time": "2020-05-12T17:14:17.917582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating accuracy directly\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size=0.1,\n",
    "                                                   random_state=1)\n",
    "\n",
    "#Predict values for training target vector\n",
    "y_hat = logit.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Binary Classifier Thresholds</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:22:48.271939Z",
     "start_time": "2020-05-12T17:22:47.993683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "#Create feature matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                      n_features=10,\n",
    "                                      n_classes=2,\n",
    "                                      n_informative=3,\n",
    "                                      random_state=3)\n",
    "\n",
    "#Split into training and test data\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "#Create classifier\n",
    "logit = LogisticRegression()\n",
    "\n",
    "#Train model\n",
    "logit.fit(features_train, target_train)\n",
    "\n",
    "#Get predicted probabilities\n",
    "target_probabilities = logit.predict_proba(features_test)[:,1]\n",
    "\n",
    "#Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities)\n",
    "\n",
    "#Plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0], c=\".7\"), plt.plot([1, 1], c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:23:40.658941Z",
     "start_time": "2020-05-12T17:23:40.650961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86891533, 0.13108467]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get predicted probabilities\n",
    "logit.predict_proba(features_test)[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:23:53.283806Z",
     "start_time": "2020-05-12T17:23:53.276829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:25:41.159858Z",
     "start_time": "2020-05-12T17:25:41.154871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5331715230155317\n",
      "True-Positive Rate: 0.810204081632653\n",
      "False Positive Rate: 0.14901960784313725\n"
     ]
    }
   ],
   "source": [
    "#Threshold of above 50%\n",
    "print(\"Threshold:\", threshold[116])\n",
    "print(\"True-Positive Rate:\", true_positive_rate[116])\n",
    "print(\"False Positive Rate:\", false_positive_rate[116])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:27:34.741681Z",
     "start_time": "2020-05-12T17:27:34.735693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.8189133876659292\n",
      "True-Positive Rate: 0.5448979591836735\n",
      "False Positive Rate: 0.047058823529411764\n"
     ]
    }
   ],
   "source": [
    "#Threshold of above 80%\n",
    "print(\"Threshold:\", threshold[45])\n",
    "print(\"True-Positive Rate:\", true_positive_rate[45])\n",
    "print(\"False Positive Rate:\", false_positive_rate[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:28:00.211702Z",
     "start_time": "2020-05-12T17:28:00.202725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9073389355742297"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate area under curver\n",
    "roc_auc_score(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Multiclass Classifier Predictions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:30:50.542829Z",
     "start_time": "2020-05-12T17:30:50.317433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264000000000001"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                      n_features = 3,\n",
    "                                      n_informative = 3,\n",
    "                                      n_redundant = 0,\n",
    "                                      n_classes = 3,\n",
    "                                      random_state = 1)\n",
    "\n",
    "#Create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "#Cross-validate model using accuracy\n",
    "cross_val_score(logit, features, target, scoring=\"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:31:49.287797Z",
     "start_time": "2020-05-12T17:31:49.053442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826180117350191"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring=\"f1_macro\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualizing a Classifier's Performance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:39:00.576006Z",
     "start_time": "2020-05-12T17:39:00.334648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib .pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "#load data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#Create feature matrix\n",
    "features = iris.data\n",
    "\n",
    "#Create target vector\n",
    "target = iris.target\n",
    "\n",
    "#Create list of target class names\n",
    "class_names = iris.target_names\n",
    "\n",
    "#Create training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=1)\n",
    "\n",
    "#Create logisitc regression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "#Train model and make prediciton\n",
    "target_predicted = classifier.fit(features_train, target_train).predict(features_test)\n",
    "\n",
    "#Create confusion matrix\n",
    "matrix = confusion_matrix(target_test, target_predicted)\n",
    "\n",
    "#Create pandas dataframe\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "#Create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Regression Models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:42:57.378051Z",
     "start_time": "2020-05-12T17:42:57.356110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1974.65337976, -2004.54137625, -3935.19355723, -1060.04361386,\n",
       "       -1598.74104702])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#generate feature matrix, target vector\n",
    "features, target = make_regression(n_samples = 100,\n",
    "                                  n_features = 3,\n",
    "                                  n_informative = 3,\n",
    "                                  n_targets = 1,\n",
    "                                  noise = 50,\n",
    "                                  coef = False,\n",
    "                                  random_state = 1)\n",
    "\n",
    "#Create a linear regression object\n",
    "ols = LinearRegression()\n",
    "\n",
    "#Cross-validate the linear regression using (negative) MSE\n",
    "cross_val_score(ols, features, target, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:43:32.159852Z",
     "start_time": "2020-05-12T17:43:32.144893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8622399 , 0.85838075, 0.74723548, 0.91354743, 0.84469331])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validate the linear regression using R-squared\n",
    "cross_val_score(ols, features, target, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Clustering Models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:48:14.503508Z",
     "start_time": "2020-05-12T17:48:14.341938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916265564072142"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "#Generate feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "                        n_features = 10,\n",
    "                        centers = 2,\n",
    "                        cluster_std = 0.5,\n",
    "                        shuffle = True,\n",
    "                        random_state = 1)\n",
    "\n",
    "#Cluster data using k-means to predict classes\n",
    "model = KMeans(n_clusters=2, random_state=1).fit(features)\n",
    "\n",
    "#Get predicted classes\n",
    "target_predicted = model.labels_\n",
    "\n",
    "#Evaluate model\n",
    "silhouette_score(features, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Custom Evaluation Metric</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:54:17.084129Z",
     "start_time": "2020-05-12T17:54:17.065499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997906102882058"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "#Generate feature matrix and target vector\n",
    "features, target = make_regression(n_samples = 100,\n",
    "                                  n_features = 3,\n",
    "                                  random_state = 1)\n",
    "\n",
    "#Create training set and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.10, random_state=1)\n",
    "\n",
    "#Create custom metric\n",
    "def custom_metric(target_test, target_predicted):\n",
    "    #Calculate r-squared score\n",
    "    r2 = r2_score(target_test, target_predicted)\n",
    "    #Return r-squared score\n",
    "    return r2\n",
    "\n",
    "#Make scorer and define that higher scores are better\n",
    "score = make_scorer(custom_metric, greater_is_better=True)\n",
    "\n",
    "#Create ridge regression model\n",
    "classifier = Ridge()\n",
    "\n",
    "#Train ridge regression model\n",
    "model = classifier.fit(features_train, target_train)\n",
    "\n",
    "#Apply custom scorer\n",
    "score(model, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T17:55:31.707389Z",
     "start_time": "2020-05-12T17:55:31.701406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997906102882058"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict values\n",
    "target_predicted = model.predict(features_test)\n",
    "\n",
    "#Calculate r-squared score\n",
    "r2_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualizing the Effect of Training Set Size</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:15:24.018306Z",
     "start_time": "2020-05-12T18:14:34.274062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "%matplotlib inline\n",
    "\n",
    "#Load data\n",
    "digits = load_digits()\n",
    "\n",
    "#Create feature matrix and target vector\n",
    "features, target = digits.data, digits.target\n",
    "\n",
    "#Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(RandomForestClassifier(), #Classifier\n",
    "                                                       features, #Feature matrix\n",
    "                                                       target, #Target vector\n",
    "                                                       cv=10, #Number of folds\n",
    "                                                       scoring=\"accuracy\", #Performance metric\n",
    "                                                       n_jobs=-1, #Use all cores\n",
    "                                                        #50 training set sizes\n",
    "                                                       train_sizes=np.linspace(0.01, 1.0, 50))\n",
    "                                                        \n",
    "#Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "#Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "#Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#111111\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color='#111111', label=\"Cross-validation score\")\n",
    "\n",
    "#Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "#Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating a Text Report of Evaluation Metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:20:00.515111Z",
     "start_time": "2020-05-12T18:20:00.462250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       1.00      0.94      0.97        16\n",
      "   virginica       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#Create feature matrix\n",
    "features = iris.data\n",
    "\n",
    "#Create target vector\n",
    "target = iris.target\n",
    "\n",
    "#Create list of target class names\n",
    "class_names = iris.target_names\n",
    "\n",
    "#Create training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=1)\n",
    "\n",
    "#Create logisitc regression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "#Train model and make predictions\n",
    "model = classifier.fit(features_train, target_train)\n",
    "target_predicted = model.predict(features_test)\n",
    "\n",
    "#Create classification report\n",
    "print(classification_report(target_test, target_predicted, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualizing the Effect of Hyperparameter Values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:37:47.013648Z",
     "start_time": "2020-05-12T18:36:46.779529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "%matplotlib inline\n",
    "\n",
    "#Load data\n",
    "digits = load_digits()\n",
    "\n",
    "#Create feature matrix and target vector\n",
    "features, target = digits.data, digits.target\n",
    "\n",
    "#Create range of values for parameter\n",
    "param_range = np.arange(1, 250, 2)\n",
    "\n",
    "#Calculate accuracy on training and test set using range of parameter values\n",
    "train_scores, test_scores = validation_curve(RandomForestClassifier(), features, target, param_name=\"n_estimators\",\n",
    "                                             param_range=param_range, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "#Calculate mean and standard deviation for training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "#Calculate the mean and strandard deviation for test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "#plot mean accuracy scores for training and test sets\n",
    "plt.plot(param_range, train_mean, label=\"Training Score\", color=\"black\")\n",
    "plt.plot(param_range, test_mean, label=\"Cross-Validation Score\", color=\"dimgrey\")\n",
    "\n",
    "#plot accuracy bands for training and test sets\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"red\")\n",
    "\n",
    "#Create plot\n",
    "plt.title(\"Validation Curve with Random Forest\")\n",
    "plt.xlabel(\"Number of Trees\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Model Selection</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting Best Models Using Exhaustive Search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:45:39.059874Z",
     "start_time": "2020-05-12T18:45:37.402539Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#Create logisitc regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "#Create range of candidate penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "#Create range of candidate regularization hyperparameter values\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "#Create dictionary hyperparameter candidates\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "#Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "#Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:47:49.480653Z",
     "start_time": "2020-05-12T18:47:49.473672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 7.742636826811269\n"
     ]
    }
   ],
   "source": [
    "#View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:48:15.244543Z",
     "start_time": "2020-05-12T18:48:15.237562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting Best Models Using Randomized Search</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:58:12.370899Z",
     "start_time": "2020-05-12T18:58:08.608091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "#Create range of candidate regularization penalty hyperparameter values\n",
    "penalty = ['l1','l2']\n",
    "\n",
    "#Create distribution of cadidate regularization hyperparameter values\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "#Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "#Create randomized search\n",
    "randomizedsearch = RandomizedSearchCV(logistic, hyperparameters, random_state=1, n_iter=100,\n",
    "                                     cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "#Fit randomized search\n",
    "best_model = randomizedsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:58:35.098254Z",
     "start_time": "2020-05-12T18:58:35.093264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 3.730229437354635\n"
     ]
    }
   ],
   "source": [
    "#View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:58:48.291509Z",
     "start_time": "2020-05-12T18:58:48.284529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting Best Models from Multiple Learning Algorithms</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T19:10:38.984045Z",
     "start_time": "2020-05-12T19:10:23.285657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "#Create a pipeline\n",
    "pipe = Pipeline([(\"Classifier\", RandomForestClassifier())])\n",
    "\n",
    "#Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "search_space = [{\"Classifier\": [LogisticRegression()], \"Classifier__penalty\": ['l1','l2'], \n",
    "                 \"Classifier__C\": np.logspace(0, 4, 10)},\n",
    "               {\"Classifier\": [RandomForestClassifier()], \"Classifier__n_estimators\": [10, 100, 1000], \n",
    "                \"Classifier__max_features\":[1, 2, 3]}]\n",
    "\n",
    "#Create grid search\n",
    "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "#Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T19:13:34.332074Z",
     "start_time": "2020-05-12T19:13:34.326092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=7.742636826811269, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View best model\n",
    "best_model.best_estimator_.get_params()[\"Classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T19:13:53.853741Z",
     "start_time": "2020-05-12T19:13:53.846763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecting Best Models When Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:11:16.412026Z",
     "start_time": "2020-05-12T20:11:13.907178Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "targets = iris.target\n",
    "\n",
    "#Create a preprocessing object that includes StandardScaler features and PCA\n",
    "preprocess = FeatureUnion([(\"std\", StandardScaler()), (\"pca\", PCA())])\n",
    "\n",
    "#Create pipeline\n",
    "pipe = Pipeline([(\"preprocess\", preprocess),\n",
    "                (\"classifier\", LogisticRegression())])\n",
    "\n",
    "#Create space of candidate values\n",
    "search_space = [{\"preprocess__pca__n_components\": [1, 2, 3],\n",
    "                \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                \"classifier__C\": np.logspace(0, 4, 10)}]\n",
    "\n",
    "#Create grid search\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "#Fit grid search\n",
    "best_model = clf.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:12:10.209544Z",
     "start_time": "2020-05-12T20:12:10.203560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View best model\n",
    "best_model.best_estimator_.get_params()[\"preprocess__pca__n_components\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Speeding Up Model Selection with Parallelization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:16:59.936620Z",
     "start_time": "2020-05-12T20:16:06.974567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4128 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 9128 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:   52.8s finished\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "features, targets = iris.data, iris.target\n",
    "\n",
    "#Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "#Create range of candidate regularization penalty hyperparameter values\n",
    "penalty = [\"l1\", \"l2\"]\n",
    "\n",
    "#Create range of candidate values for X\n",
    "C = np.logspace(0, 4, 1000)\n",
    "\n",
    "#Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "#Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "#Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Speeding Up Model Selection Using Algorithm-Specific Methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:19:51.984498Z",
     "start_time": "2020-05-12T20:19:44.157560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=100, class_weight=None, cv=None, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "features, targets = iris.data, iris.target\n",
    "\n",
    "#Create cross-validated logistic regression\n",
    "logit = linear_model.LogisticRegressionCV(Cs=100)\n",
    "\n",
    "#Train model\n",
    "logit.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating Performance After Model Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:24:09.544064Z",
     "start_time": "2020-05-12T20:24:03.187048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\nhundley\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "#Load data\n",
    "iris = datasets.load_iris()\n",
    "features, targets = iris.data, iris.target\n",
    "\n",
    "#Create logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "#Create range of candidate values for X\n",
    "C = np.logspace(0, 4, 20)\n",
    "\n",
    "#Create hyperparameter options\n",
    "hyperparameters = dict(C=C)\n",
    "\n",
    "#Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "#Conduct nested cross-validation and output the average score\n",
    "cross_val_score(gridsearch, features, target).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2>Linear Regression</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fitting a Line</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:34:01.314328Z",
     "start_time": "2020-05-12T20:34:01.296377Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "#Load data with only two features\n",
    "boston = load_boston()\n",
    "features = boston.data[:,0:2]\n",
    "targets = boston.target\n",
    "\n",
    "#Create linear regression\n",
    "regression = LinearRegression()\n",
    "\n",
    "#Fit the linear regression\n",
    "model = regression.fit(features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:34:17.071886Z",
     "start_time": "2020-05-12T20:34:17.065902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.485628113468223"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the intercept\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:34:31.678844Z",
     "start_time": "2020-05-12T20:34:31.672861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35207832,  0.11610909])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the feature coefficients\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:35:13.143102Z",
     "start_time": "2020-05-12T20:35:13.137102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First value in the target vector multiplied by 1000\n",
    "targets[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:35:44.672713Z",
     "start_time": "2020-05-12T20:35:44.665763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24573.366631705547"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the target value of the first observation, multiplied by 1000\n",
    "model.predict(features)[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T20:36:31.047838Z",
     "start_time": "2020-05-12T20:36:31.042851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-352.07831564026765"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First coefficient multiplied by 1000\n",
    "model.coef_[0]*1000\n",
    "\n",
    "#Every single crime per capita will decrease the price of the house by approximately $350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Handling Interactive Effects</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:00:27.469011Z",
     "start_time": "2020-05-13T18:00:27.434103Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Load data\n",
    "boston = load_boston()\n",
    "features = boston.data[:,0:2]\n",
    "target = boston.target\n",
    "\n",
    "#Create interaction term\n",
    "interaction = PolynomialFeatures(degree=3, include_bias=False, interaction_only=True)\n",
    "features_interaction = interaction.fit_transform(features)\n",
    "\n",
    "#Create linear regression\n",
    "regression = LinearRegression()\n",
    "\n",
    "#Fit the linear regression\n",
    "model = regression.fit(features_interaction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:00:56.131984Z",
     "start_time": "2020-05-13T18:00:56.124003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.32e-03, 1.80e+01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the feature values for first observation\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:02:14.848536Z",
     "start_time": "2020-05-13T18:02:14.841549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11376"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#For each observation, multiply the values of the first and second feature\n",
    "interaction_term = np.multiply(features[:,0], features[:,1])\n",
    "\n",
    "#View interaction term for first observation\n",
    "interaction_term[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T18:03:16.909834Z",
     "start_time": "2020-05-13T18:03:16.905840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.3200e-03, 1.8000e+01, 1.1376e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the values of the first observation\n",
    "features_interaction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fitting a Nonlinear Relationship</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Load data\n",
    "boston = load_boston()\n",
    "features = boston.data[:,0:1]\n",
    "target = boston.target\n",
    "\n",
    "#Create polynomial features x^2 and x^3\n",
    "polynomial = PolynomialFeatures(degree=3, include_bias=False)\n",
    "features_polynomial = polynomial.fit_transform(features)\n",
    "\n",
    "#Create linear regression\n",
    "regression = LinearRegression()\n",
    "\n",
    "#Fit the linear regression\n",
    "model = regression.fit(features_polynomial, target)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "206.997px",
    "width": "325.573px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285.556px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
